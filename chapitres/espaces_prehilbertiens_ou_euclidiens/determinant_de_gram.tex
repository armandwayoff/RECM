\begin{defi}
    Soit $E$ un espace euclidien et $(x_1, \dots, x_p)$ une famille d'éléments de $E$. On définit
    $$\text{la matrice de \textsc{Gram} } \Gram \defeq \left( \langle x_i, x_j \rangle \right)_{i,j \in \llbracket 1, p \rrbracket}$$
    $$\text{le déterminant de \textsc{Gram} } \Gram(x_1, \dots, x_p) \defeq \det \Gram.$$
\end{defi}

\marginnote{Le déterminant de \textsc{Gram} permet de calculer des volumes et de tester l'indépendance linéaire d'une famille de vecteurs.}

\begin{remarque}
    La matrice $\Gram$ est symétrique.
\end{remarque}

\begin{prop}
     La famille $(x_1, \dots, x_p)$ est liée si et seulement si $\Gram(x_1, \dots, x_p) = 0$.
\end{prop}

\begin{preuve}
    $(\Rightarrow)$ Il existe une famille $(\lambda_1, \dots, \lambda_p)$ non nulle  de $\R^n$ telle que $\sum\limits_{i=1}^{p} \lambda_i x_i = 0$. On montre alors que pour toute ligne $L_i$ de $\Gram$, $\sum\limits_{i=1}^{p} \lambda_i L_i = 0$ ce qui permet de conclure. \\
    $(\Leftarrow)$ Raisonner par contraposée, on suppose $\mathscr{F} = (x_1, \dots, x_p)$ libre. \\
    Soit $\mathscr{B} = (\varepsilon_1, \dots, \varepsilon_n)$ une b.o.n. de $E$ et $H \in \M_{n, p} (\R)$ la matrice de $\mathscr{F}$ dans $\mathscr{B}$. \\
    Alors $\boxed{\Trsp{H} H = \Gram(x_1, \dots, x_p)}$. \\
    Montrons la chaîne :
    $$\Rg(G) = \underbrace{\Rg(\Trsp{H} H) = \Rg(H)}_{\text{à montrer}} = \Rg(\mathscr{F}) = p \not= 0$$
    Montrer que $\Rg(\Trsp{H} H) = \Rg(H)$ en montrant que $\Ker(\Trsp{H} H) = \Ker(H)$. 
    \begin{itemize}
        \item $(\subset)$ oui
        \item $(\supset)$ Soit $X \in \Ker(\Trsp{H}H)$. On montre que $\norme{BX} = 0 \Rightarrow BX = 0$. 
    \end{itemize}
    Par le \textbf{théorème du rang}, on obtient le résultat. 
\end{preuve}

\begin{theo} \label{distance_a_un_sous_espace_vectoriel}
    Distance à un sous-espace vectoriel \\
    Soit $(E, \langle \cdot , \cdot \rangle)$ un espace préhilbertien. \\
    Soit $F$ un sous-espace vectoriel de $E$ de dimension finie $p \in \Ne$ et soit $(e_1, \dots, e_p)$ une base de $F$. Alors pour tout $x \in E$,
    $$d(x, F)^2 = \frac{\Gram(e_1, \dots, e_p, x)}{\Gram(e_1, \dots, e_p)}.$$
\end{theo}

\begin{preuve}
    Soit $\pi_F(x)$ le projeté orthogonal de $x$ sur $F$. \\
    Alors $d(x, F)^2 = \norme{x - \pi_F(x)}^2$ et par \textsc{Pythagore}, $\norme{x}^2 = \norme{\pi_F(x)}^2 + \norme{x - \pi_F(x)}^2$. De plus, pour tout $k \in \llbracket 1, p \rrbracket$, $\langle x , e_k \rangle = \langle \pi_F(x) , e_k \rangle$. On obtient alors
    \begin{align*}
        \Gram(e_1, \dots, e_p, x) &= 
        \begin{vmatrix}
          \begin{matrix}
            & & \\
            & \langle e_i, e_j \rangle & \\
            & &
          \end{matrix}
          & \rvline & \langle e_i, x \rangle \\
        \hline
          \langle x, e_j \rangle & \rvline &
          \begin{matrix}
          \norme{x}^2
          \end{matrix}
        \end{vmatrix} \\
        &=
        \begin{vmatrix}
          \begin{matrix}
            & & \\
            & \langle e_i, e_j \rangle & \\
            & &
          \end{matrix}
          & \rvline & \langle e_i, \pi_F(x) \rangle + 0 \\
        \hline
          \langle x, e_j \rangle & \rvline &
          \begin{matrix}
          \norme{\pi_F(x)}^2 + \norme{x - \pi_F(x)}^2
          \end{matrix}
        \end{vmatrix} 
    \end{align*}
    Par linéarité du déterminant par rapport à la dernière colonne on obtient
    $$\Gram(e_1, \dots, e_p, x) = \Gram(e_1, \dots, e_p, \pi_F(x)) + \norme{x - \pi_F(x)}^2 \Gram(e_1, \dots, e_p).$$
    Comme $\pi_F(x) \in \Vect(e_1, \dots, e_p)$, le premier terme est nul et donc $\Gram(e_1, \dots, e_p, x) = d(x, F)^2 \Gram(e_1, \dots, e_p)$ soit 
    $$d(x, F)^2 = \frac{\Gram(e_1, \dots, e_p, x)}{\Gram(e_1, \dots, e_p)}.$$
\end{preuve}

\begin{corol} \label{inegalite_gram}
    Soit $(x_1, \dots, x_n) \in E^n$. Alors,
    $$\Gram(x_1, \dots, x_n) \leqslant \prod_{i=1}^n \norme{x_i}^2$$
    avec égalité si et seulement si la famille $(x_1, \dots, x_n)$ est liée. 
\end{corol}

\begin{preuve}
Jérôme Von Buhren \\
    Si la famille $(x_1, \dots, x_n)$ est liée, le résultat est immédiat. \\
    Raisonnons par récurrence sur $n \in \Ne$ sur la propriété
    \begin{center}
        $\mathscr{P}_n$: \say{ pour toute famille libre $(x_1, \dots, x_n)$ de $E$, on a $\Gram(x_1, \dots, x_n) \leqslant \prod\limits_{i=1}^n \norme{x_i}^2$ }.
    \end{center}
    \underline{Initialisation pour $n = 1$:} soit $x_1 \in E$. $\Gram(x_1) = \langle x_1, x_1 \rangle = \norme{x_1}^2$ donc $\mathscr{P}_1$ est vérifiée. \\
    \underline{Hérédité:} supponsons $\mathscr{P}_n$ vraie. Soit $(x_1, \dots, x_n, x_{n+1})$ une famille libre de $E$. En notant $F \defeq \Vect(x_1, \dots, x_n)$, il existe $(f, \tilde{f}) \in F \times F^\perp$ tel que $x_{n+1} = f + \Tilde{f}$. Par le theorème (\nameref{distance_a_un_sous_espace_vectoriel}) et par $\mathscr{P}_n$, 
    $$\Gram(x_1, \dots, x_{n+1}) = \Gram(x_1, \dots, x_n) \norme{\tilde{f}} \leqslant \norme{x_1}^2 \cdots \norme{x_n}^2 \norme{x_{n+1}}^2$$
    car par le théorème de \textsc{Pythagore}, $\norme{\tilde{f}} \leqslant \norme{x_{n+1}}$. On conclut que $\mathscr{P}_{n+1}$ est vraie, d'où le résultat. 
\end{preuve}

\begin{prop}
    La matrice de \textsc{Gram} est symétrique positive.
\end{prop}

\begin{preuve}
    \begin{itemize}
        \item La matrice de \textsc{Gram} est symétrique par symétrie du produit scalaire.
        \item Montrons la positivité de $\Gram$. Soit $X = \Trsp{(\alpha_1 \cdots \alpha_n)} \in \M_{n,1}(\R)$. Montrons que $\Trsp{X} \Gram X \geqslant 0$. 
        \begin{align*}
            \Trsp{X} \Gram X &= \sum_{i=1}^{n} \sum_{j=1}^{n} \langle x_i, x_j \rangle \alpha_i \alpha_j \\ 
            &= \sum_{i=1}^{n} \sum_{j=1}^{n} \langle \alpha_i x_i, \alpha_j x_j \rangle \\
            &= \left\Vert \sum_{i=1}^{n}x_i \alpha_i \right\Vert^2 \geqslant 0.
        \end{align*}
    \end{itemize}
   
    Ce qui montre bien que $\Gram$ est symétrique positive.
\end{preuve}

\marginnote[-10cm]{
    \begin{kaobox}[frametitle=Matrices symétriques positives]
        L'ensemble des \emph{matrices symétriques positives} est noté $\mathscr{S}_n^+(\R)$. Une matrice $M \in \mathscr{S}_n^+(\R)$ équivaut à chacune des propriétés suivantes:
        \begin{itemize}
            \item pour tout $X \in \M_n(\R), \Trsp{X} M X \geqslant 0$,
            \item $\Sp(M) \subset \Rp.$
        \end{itemize}
    \end{kaobox}
}
