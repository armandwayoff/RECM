\chapter{Algèbre linéaire, Matrices}
\labch{algebre_lineaire_matrices}

\input{chapitres/algebre_lineaire_matrices/intro}

\newpage

% \section{Cours: changement de base}
% \begin{marginfigure}
%     \input{illustrations/i_changement_de_base}
% \end{marginfigure}

Faisons la transition entre le chapitre sur les polynômes et celui sur l'algèbre linéaire en revenant sur les polynômes de \textsc{Hilbert}.

\section{Polynômes de \textsc{Hilbert}} \label{polynome_hilbert}
\input{chapitres/algebre_lineaire_matrices/polynomes_de_hilbert}

\section{Polynômes de \textsc{Lagrange}} 
\input{chapitres/algebre_lineaire_matrices/polynomes_de_lagrange}

\section{Matrice de \textsc{Vandermonde}} %%%%%%%%%%%%%%%%%%%%%%%%%%%%
\input{chapitres/determinants/matrice_de_vandermonde}

\section{Centre de \texorpdfstring{$\M_n(\K)$}{l'espace des matrices carrées}}
\input{chapitres/algebre_lineaire_matrices/centre_de_l_espace_des_matrices_carres}

\section{Semblables sur \texorpdfstring{$\C$, sur $\R$}{C, sur R}}
\input{chapitres/algebre_lineaire_matrices/semblables_sur_C_sur_R}

\section{Noyaux itérés}
\input{chapitres/algebre_lineaire_matrices/noyaux_iteres}

\section{Applications de \texorpdfstring{$\M_n(\K) \to \K$}{l'espace des matrices carrées dans le corps K} conservant le produit}
\input{chapitres/algebre_lineaire_matrices/applications_de_l_espace_des_matrices_carrees_dans_le_corps_K_conservant_le_produit}

\section{Matrices compagnon}
\input{chapitres/algebre_lineaire_matrices/matrices_compagnon}

\section{Caractérisation des homothéties}
\input{chapitres/algebre_lineaire_matrices/caracterisation_des_homotheties}

\section{Inversion par sommation géométrique des endomorphismes nilpotents} \labsec{inversion_par_sommation_geometrique_des_endomorphismes_nilpotents}
\input{chapitres/algebre_lineaire_matrices/inversion_par_sommation_geometrique_des_endomorphismes_nilpotents}

\section{Matrices de taille \texorpdfstring{$3$}{3} d'ordre de nilpotence égal à \texorpdfstring{$2$}{2}} \labsec{matrices_de_taille_trois_odre_de_nilpotence_deux}
\input{chapitres/algebre_lineaire_matrices/matrices_de_taille_trois_odre_de_nilpotence_deux}

\section{Famille libre engendrée par un endomorphisme nilpotent} \labsec{famille_libre_engendree_par_un_endomorphisme_nilpotent}
\input{chapitres/algebre_lineaire_matrices/famille_libre_engendree_par_un_endomorphisme_nilpotent}

\section{Matrices de rang \texorpdfstring{$1$}{1}}
\input{chapitres/algebre_lineaire_matrices/matrices_de_rang_un}

\section{Sous-espace engendré par les matrices nilpotentes} \labsec{sous_espace_engendre_par_les_matrices_nilpotentes}
\input{chapitres/algebre_lineaire_matrices/sous_espace_engendre_par_les_matrices_nilpotentes}

\section{Produit de matrices nilpotentes commutantes} \labsec{titre_a_completer}
\begin{exercice}
    \marginnote[0cm]{Source : \cite{acamanes}}
    Soient $A$ et $B$ deux matrices de $\M_n(\C)$ qui commutent. 
    \begin{enumerate}
        \item On suppose que $B$ est nilpotente. 
        \begin{enumerate}
            \item Montrer que $A + B$ est inversible si et seulement si $A$ est inversible.
            \item Montrer que $\det(A+B) = \det(A)$.
        \end{enumerate}
        \item Soient $A_1, \dots, A_n$ des matrices nilpotentes qui commutent deux à deux. Montrer que $A_1 \times \cdots \times A_n = 0$.
    \end{enumerate}
\end{exercice}

\begin{solution}
    \marginnote[0cm]{Source : \cite{maths-france} Planche no 5. Réduction. Corrigé}
    \begin{itemize}
        \item[$\rhd$] Si $u$ est inversible,
        $$\det(u+v) = \det(u) \Leftrightarrow \det(u) \times \det(\Id + \Inv{u}v) = \det(u) \Leftrightarrow \det(\Id + \Inv{u}v) = 1.$$
        Les endomorphismes $u$ et $v$ commutent et donc $\Inv{u}$ et $v$ également \note. 
        \marginnote[0cm]{
            \begin{align*}
                \note
                u \circ v &= v \circ u \\
                \Rightarrow v &= \Inv{u} \circ v \circ u \\
                \Rightarrow v \circ \Inv{u} &= \Inv{u} \circ v
            \end{align*}
        }
        Mais alors, puisque $v$ est nilpotent, l'endomorphisme $w \defeq \Inv{u}v$ l'est également. Il reste donc à calculer $\det(\Id + w)$ où $w$ est un endomorphisme nilpotent. On remarque que $\det(\Id + w) = (-1)^n \chi_w(-1)$. Il est connu que $0$ est l'unique valeur propre d'un endomorphisme nilpotent et donc $\chi_w = X^n$ puis $\det(\Id+w) = 1$. Le résultat est donc démontré dans le cas où $u$ est inversible. \item[$\rhd$] Si $u$ n'est pas inversible, $u + x \Id$ est inversible sauf pour un nombre fini de valeurs de $x$ et commute toujours avec $v$. Donc, pour tout $x$ sauf peut-être pour un nombre fini, $\det(u + x \Id + v) = \det(u + x \Id)$. Ces deux polynômes coïncident en une infinité de valeurs de $x$ et sont donc égaux. Ils prennent en particulier la même valeur en $0$ ce qui refournit $\det(u+v) = \det u$.
    \end{itemize}    
\end{solution}

\begin{solution}
    \begin{enumerate}
        \item Comme les matrices $A$ et $B$ commutent, elles sont cotrigonalisables (lien vers l'exercice correspondant). De plus comme la matrice $B$ est nilpotente, dans toute base dans laquelle elle est triangulaire, sa diagonale est nulle (le spectre d'une matrice nilpotente est réduit à $0$). Ainsi dans une base de cotrigonalisation des matrices $A+B$ et $A$, leur diagonale sont égales et donc leur déterminant (qui sont égaux au produit des termes diagonaux).
        \marginnote[0cm]{
            $$A + B \sim 
            \begin{pmatrix}
                \lambda_1 & \cdots & \star \\
                0 & \ddots & \vdots \\
                0 & 0 & \lambda_n
            \end{pmatrix}
             + 
            \begin{pmatrix}
                0 & \star & \star \\
                0 & \ddots & \star \\
                0 & 0 & 0
            \end{pmatrix}
            $$
        }
        \item \marginnote[0cm]{Source : \cite{reduc_des_endo} p. 117}
        Comme les matrices $A_1, \dots, A_n$ sont trigonalisables et commutent, elles sont cotrigonalisables: il existe donc $T_1, \dots, T_n$ triangulaires supérieures strictes et $P$ inversible telles que $A_i = P T_i \Inv{P_i}$ pour tout $i \in \llbracket 1, n \rrbracket$. \\
        Montrons par récurrence sur $k \in \llbracket 1, n \rrbracket$ que les coefficients en position $(i, j)$ avec $i \geqslant j - k + 1$ de la matrice $T_1 \cdots T_k$ sont nuls. 
        \begin{itemize}
            \item Pour $k=1$, il s'agit simplement de la définition d'une matrice triangulaire supérieure stricte. 
            \item Soit $k \in \llbracket 1, n-1 \rrbracket$ telle que les coefficients en position $(i, j)$ avec $i \geqslant j - k + 1$ de la matrice $T_1 \cdots T_k$ sont nuls. \\
            Soit $(i, j)$ tel que $i \geqslant j - k$. Avec des notation évidentes, 
            \begin{align*}
                [T_1 \cdots T_{k+1}]_{i,j} &= \sum_{\ell=1}^n [T_1 \cdots T_k]_{i, \ell} [T_{k+1}]_{\ell, j} \\
                \text{ comme } T_{k+1} \in \mathscr{T}_n^{++} &= \sum_{\ell=1}^{j-1} [T_1 \cdots T_k]_{i, \ell} [T_{k+1}]_{\ell, j} \\
                &= 0, \text{ car } i \geqslant \ell - k +1.
            \end{align*}
            La récurrence est terminée et l'on en déduit en considérant le cas $k = n$ que la matrice $T_1 \cdots T_n$ est nulle. En conclusion,
            $$A_1 \cdots A_n = P T_1 \cdots T_n \Inv{P} = 0.$$
        \end{itemize}
        \underline{Deuxième démonstration:} \\
        \begin{lemme}
            \marginnote[0cm]{Source : \cite{reduc_des_endo} p. 33}
            Soit $u$ et $n$ deux endomorphismes de $E$ tels que $u$ est non nul, $n$ est nilpotent et $u \circ n = n \circ u$. Montrer que $\Rg(u \circ n) < \Rg(u)$.
        \end{lemme}
        \begin{preuve}
            Comme $u$ et $n$ commutent, $n$ laisse stable $\Im u$. Notons $\widetilde{n}$ l'endomorphisme induit par $n$ sur $\Im u$. Comme $n$ est nilpotent, $\widetilde{n}$ est également nilpotent et donc, en particulier, non inversible. \\
            La formule du rang appliquée à $\widetilde{n}$ donne alors:
            $$\Rg u = \dim \Im u = \Rg \widetilde{n} + \dim \Ker \widetilde{n} > \Rg \widetilde{n}.$$
            On conclut en remarquant que $\Im \widetilde{n} = n(\Im u) = \Im (n \circ u)$.
        \end{preuve}
    \end{enumerate}
    Revenons à la démonstration du résultat. \\
    Soit $A_1, \dots, A_n$ des matrices nilpotentes qui commutent deux à deux. On suppose qu'elles sont toutes non nulles car si ça n'est pas le cas, le résultat est immédiat. \\
    D'après le lemme,
    $$0 \leqslant \Rg(A_1 \cdots A_n) < \Rg(A_1 \cdots A_{n-1}) < \cdots < \Rg(A_1) < n.$$
    Donc $\Rg(A_1 \cdots A_n) = 0$ et $A_1 \cdots A_n$ est la matrice nulle.
\end{solution}


\section{Si \texorpdfstring{$AB - BA = A \dots$}{AB-BA=A...}}
\begin{exercice}
    \marginnote[0cm]{Source : \href{http://exo7.emath.fr/ficpdf/fic00118.pdf}{Exercices de J.-L. \textsc{Rouget} (fic00118 exo 28)}}
    Soient $n \in \Ne$, $A$ et $B$ deux matrices de $\M_n(\R)$ telles que $AB - BA = A$. Montrer que pour tout $p \in \Ne$, $\Tr(A^p) = 0$.
\end{exercice}

\marginnote[2cm]{
    \begin{prop}{Propriétés de la trace}
        Soit $(A, B) \in \M_n(\K)^2$.
        \begin{align*}
            \Tr(AB) &= \Tr(BA), \\
            \Tr(A + \lambda B) &= \Tr(A) + \lambda \Tr(B).
        \end{align*}
    \end{prop}
}

\begin{solution}
    Soit $p \in \Ne$. On écrit
    \begin{align*}
        A^p = A^{p-1}(AB-BA) = A^pB - A^{p-1}BA.
    \end{align*}
    On composant cette relation par la trace on obtient d'après ses propriétés
    \begin{align*}
        \Tr(A^p) &= \Tr(A^pB) - \Tr \big((A^{p-1}B)A \big) \\
        &= \Tr(A^pB) - \Tr \big(A(A^{p-1}B) \big) \\
        \Tr(A^p) &= 0.
    \end{align*}
\end{solution}

\begin{exercice} \labexercice{a_comp}
    \marginnote[0cm]{Source : \cite{exos_oraux} p. 47}
    Soient $n \in \Ne$, $A$ et $B$ deux matrices de $\M_n(\R)$ telles que $AB - BA = A.$
    \begin{enumerate}
        \item Montrer que la matrice $A$ n'est pas inversible.
        \item Montrer que pour tout $k \in \Ne$, $AB^k - B^k A = k A^k$. En déduire que la matrice $B$ est nilpotente. 
    \end{enumerate}
\end{exercice}

\section{Application du théorème de recollement}

\begin{exercice}
    \marginnote[0cm]{Source : \cite{acamanes}}
    Soient $E$ et $F$ deux espaces vectoriels de dimension finie et $f \in \Endo(E, F)$. On note 
    $$\mathscr{H} \defeq \ens[\Big]{ g \in \Endo(F, E) \tq f \circ g \circ f = 0}.$$ 
    Déterminer la dimension de $\mathscr{H}$ en fonction de $\dim E$, $\dim F$ et $\Rg f$.
\end{exercice}

\marginnote[0cm]{
    Source : \cite{acamanes} Ch3, Th2
    \begin{theo}{Sommes directe \& Applications linéaires}
        On suppose que $E = \bigoplus\limits_{i=1}^m E_i$. Pour tout indice $i \in \llbracket 1, m \rrbracket$, on considère une application linéaire $\varphi_i$ de $E_i$ dans $F$. Alors, il existe une unique application linéaire $\varphi$ de $E$ dans $F$ telle que pour tout $i \in \llbracket 1, m \rrbracket$, la restriction de $\varphi$ à $E_i$ soit égale à $\varphi$.
    \end{theo}
}

\begin{solution}
    \begin{itemize}
        \item On montre que $\mathscr{H}$ est un sous-espace vectoriel de $\Endo(F, E)$. Soit $W$ un supplémentaire de $\Im f$ dans $F$.
        \item Nous allons construire un isomorphisme entre $\mathscr{H}$ et un ensemble dont on peut calculer la dimension \note. 
        \marginnote[0cm]{
            \begin{methode}
                \note
            \end{methode}
        }
        On pose
        $$
            \fonction[\psi]{\mathscr{H}}{\Endo(\Im f, \Ker f) \times \Endo(W, E)}{g}{\left(g_{\vert \Im f}, g_{\vert \Ker f} \right)}.
        $$
        Montrons que $\psi$ est un isomorphisme. 
        \begin{itemize}
            \item[$\rhd$] Montrons que $\psi$ est bien définie: \\
            soient $x \in E$ et $g \in \mathscr{H}$,
            $$\psi(g)(x) = \left( g_{\vert \Im f}(x), g_{\vert W}(x) \right).$$
            De plus, $\Im g \circ f \subset \Ker f$ donc $g_{\vert \Im f} \in \Endo(\Im f, \Ker f)$.
            $$(f \circ g \circ f)(x) = f \Big( g \big (\underbrace{f(x)}_{\defeq y} \big ) \Big) = f \big( \underbrace{g_{\vert \Im f}(y)}_{\in \Ker f} \big) = 0.$$
            La linéarité est triviale. 
            \item[$\rhd$] Montrons que $\psi$ est surjective. \\
            Soit $(g_1, g_2) \in \Endo(\Im f, \Ker f) \times \Endo(W, E)$. \\
            Par théorème de recollement des applications linéaires, il existe une application $g \in \Endo(F, E)$ telle que 
            $
            \begin{cases}
                    g_{\vert \Im f} = g_1 \\
                    g_{\vert W} = g_2
            \end{cases}
            $. \\
            Soit $x \in E$, $(f \circ g \circ f)(x) = f \Big( g \big(\underbrace{f(x)}_{\in \Im f} \big) \Big) = f \Big( \underbrace{g_1 \big(f(x) \big)}_{\in \Ker f} \Big) = 0$ donc $g \in \mathscr{H}$ et $\psi$ est sujective. 
            \item[$\rhd$] Montrons que $\psi$ est injective. \\
            Soit $g \in \Ker \psi$. Alors $\left (g_{\vert \Im f}, g_{\vert W} \right) = \left(0_{\Endo(F, E)}, 0_{\Endo(F, E)} \right)$. \\
            Donc $g = 0_{\Endo(F, E)}$ et $\Ker \psi = \{ 0_{\Endo(F, E)} \}$ soit $\psi$ est injective. \\
            Finalement, $\psi$ est un isomorphisme. \\
            Il y a donc égalité des dimensions entre les espaces de départ et d'arrivée de $\psi$. Ainsi,
            \begin{align*}
                \dim \mathscr{H} &= \dim \big(\Endo(\Im f, \Ker f) \big) + \dim \big( \Endo(W, E) \big) \\
                &= \Rg f \times \dim \Ker f + \dim W \times \dim E \\
                &= \Rg f \times (\dim E - \Rg f) + (\dim F - \Rg f) \times \dim E \\
                \dim \mathscr{H} &= \dim E \dim F - (\Rg f)^2
            \end{align*}
        \end{itemize}
        \begin{remarque}
            Si $\dim E = \dim F$ et que $f$ est bijective, le résultat est cohérent. De même si $f = 0_{\Endo(E, F)}$.
        \end{remarque}
    \end{itemize}
\end{solution}

\underline{Une solution plus visuelle:}

\begin{solution}
    Soit $W$ un supplémentaire de $\Im f$ dans $F$: $\Im f \oplus W = F$ et soit $V$ un supplémentaire de $\Ker f$ dans $E$: $\Ker f \oplus V = E$. \\
    Soit $\mathscr{B} \defeq (e_1, \dots, e_r, e_{r+1}, \dots, e_p)$ une base adaptée à la décomposition $\Im f \oplus W = F$ et soit $\mathscr{B}' \defeq (\varepsilon_1, \dots, \varepsilon_{n-r}, \varepsilon_{n-r+1}, \dots, \varepsilon_n)$ une base adaptée à la décomposition $\Ker f \oplus V = E$.
    \begin{align*}
        g \in \mathscr{H} &\iff g(\Im f) \subset \Ker f \\
        &\iff \Mat_{\mathscr{B}, \mathscr{B}'}(g) = 
        \begin{pmatrix}
            \star & \star \\
            0 & \star
        \end{pmatrix}
    \end{align*}
    à finir....
\end{solution}

\section{Rang des puissances d'un endomorphisme nilpotent} \labsec{rang_des_puissances_d_un_endomorphisme_nilpotent}
\begin{exercice}
    \marginnote[0cm]{Source : \cite{reduc_des_endo}}
    Soient $E$ un $\K$-espace espace vectoriel de dimension $n$ et $u \in \Endo(E)$ nilpotent de rang $n-1$. Déterminer le rang $u^k$ pour $k \in \Ne$. 
\end{exercice}

\begin{solution}
    On a, par hypothèse, $\dim(\Ker u) = 1$ et la chaîne d'inclusions
    $$\{0\} = \Ker(u^0) \subset \Ker(u) \subset \cdots \subset \Ker(u^{n-1}) \subset \Ker(u^n) = E$$
    puis, pour tout $k \geqslant n, \Ker(u^n) = E$. \\
    Si $k \in \llbracket 0, n \rrbracket$ alors 
    $$
        \fonction[u_k]{\Ker(u^{k+1})}{\Ker(u^k)}{x}{u(x)}
    $$
    définit une application linéaire dont le noyau est $\Ker(u^{k+1}) \cap \Ker(u)$, soit $\Ker(u)$. \\
    Le théorème de rang fournit $\dim(\Ker u^k) \geqslant \Rg u_k = \dim( \Ker u^{k+1}) - 1$ d'où $\dim(\Ker u^{k+1}) - \dim(\Ker u^k) \in \{ 0, 1 \}$. \\
    On en déduit déjà que pour tout $k \in \llbracket 0, n \rrbracket, \dim(\Ker u^k) \leqslant k$. \\
    S'il existe $k$ dans $\llbracket 0, n-1 \rrbracket$ pour lequel $\dim( \Ker u^{k+1}) = \dim(\Ker u^k)$ alors $\Ker u^k = \Ker u^{k+1}$ et, pour $p \in \N$, 
    ...
\end{solution}

\section{Rang d'un endomorphisme nilpotent} \labsec{rang_d_un_endomorphisme_nilpotent}
\begin{exercice}
    Soient $E$ un $\K$-espace vectoriel de dimension $n$, $u \in \Endo(E)$ tel que $u^n = 0$ et $u^{n-1} \not= 0$. Déterminer le rang de $u$.
\end{exercice}

Il s'agit de la réciproque de l'exercice précédent.

\begin{solution}
    D'après l'exercice \textcolor{red}{référence} il existe $x_0 \in E$ tel que la famille $\left( u^k(x_0)\right)_{0 \leqslant k \leqslant n-1}$ est une base de $E$. La matrice de $u$ dans cette base est 
    $$
    \begin{pmatrix}
        0 & \cdots & \cdots & 0 \\
        1 & \ddots & & \vdots \\
        & \ddots & \ddots & \vdots \\
        0 & & 1 & 0
    \end{pmatrix},
    $$
    une matrice de rang $n-1$.
\end{solution}

\section{\cite{maths-france} Planche no 3. Révision algèbre linéaire. Matrices}

\begin{exercice}
    \marginnote[0cm]{Source : \cite{maths-france} Planche no 2. Révisions algèbre linéaire. Espaces vectoriels}
    Soient $E$ un $\C$-espace vectoriel non nul de dimension finie $n$ et $f$ un endomorphisme de $E$ tel que pour tout $x \in E$, il existe $p \in \Ne$ tel que $f^p(x) = 0$. Montrer que $f$ est nilpotent. 
\end{exercice}

\begin{exercice}
    Soient $E \defeq \K_n[X]$ et $u$ est l'endomorphisme de $E$ défini par: $\forall P \in E, u(P) = P(X+1) - P$.
    \begin{enumerate}
        \item Déterminer $\Ker u$ et $\Im u$.
        \item Déterminer explicitement une base de $E$ dans laquelle la matrice de $u$ s'écrit 
        $$
        \begin{pmatrix}
            0 & 1 & 0 & \cdots & 0 \\
            \vdots & \ddots & \ddots & \ddots & \vdots \\
            \vdots & & & \ddots & 0 \\
            \vdots & & & \ddots & 1 \\
            0 & \cdots & & \cdots & 0
        \end{pmatrix}
        .$$
    \end{enumerate}
\end{exercice}

\begin{exercice}
    Calculer l'inverse de la matrice
    $$
    \begin{pmatrix}
        \binom{0}{0} & \binom{1}{0} & \binom{2}{0} & \cdots & \binom{n-1}{0} & \binom{n}{0} \\
        0 & \binom{1}{1} & \binom{2}{1} & \cdots & \cdots & \binom{n}{1} \\
        \vdots & \ddots & \binom{2}{2} & & & \vdots \\
        & & & & \ddots & & \\
        & & & & & & \\
        0 & \cdots & & \cdots & 0 & \binom{n}{n}
    \end{pmatrix}
    $$.
\end{exercice}

\begin{exercice}
    Soit $A \in \M_n(\K)$. Calculer le déterminant de sa comatrice. 
\end{exercice}

\begin{solution}
    On a toujours $A \Trsp{\com A} = \det(A) \I_n$. Par passage au déterminant et puisqu'une matrice a même déterminant que sa transposée, on obtient
    $$\det(A) \det (\com A) = (\det A)^n.$$
    \begin{itemize}
        \item Si $\det A \not = 0$, on en déduit que $\det(\com A) = (\det A)^{n-1}$.
        \item Si $\det A = 0$, alors $A \Trsp{\com A} = 0$ et donc $\Trsp{\com A}$ est soit nulle, soit diviseur de zéro, et donc dans touts les cas non inversible. Il en est de même de $\com A$ et donc $\det (\com A) = 0 = (\det A)^{n-1}$. Finalement,
        $$\forall A \in \M_n(\R), \det(\com A) = (\det A)^{n-1}.$$
    \end{itemize}
\end{solution}

\begin{exercice}
    Soit $A \in \M_n(\K)$. Étudier le rang la comatrice de $A$ en fonction du rang de $A$.
\end{exercice}

\begin{exercice}
    Existe-t-il deux matrices carrées $A$ et $B$ telles que $AB-BA = \I_n$.
\end{exercice}

\begin{solution}
    Soit $n \in \Ne$. Supposons qu'il existe deux matrices $A$ et $B$ dans $\M_n(\K)$ telles que $AB-BA=\I_n$. Alors, en composant cette relation par la trace on obtient, par linéarité,
    $$\Tr(AB) - \Tr(BA) = n, $$
    or $\Tr(AB) = \Tr(BA)$ donc on aboutit à $n = 0$ ce qui est absurde. \\
    Finalement, il n'existe pas de tel couple. 
\end{solution}

\begin{exercice}
    Soit $f$ une forme linéaire sur $\M_n(\C)$ ($n\geqslant2$) telle que $\forall (A, B) \in \M_n(\C), f(AB) = f(BA)$. Montrer qu'il existe un complexe $\alpha$ tel que $f = \alpha \Tr$.
\end{exercice}

\begin{exercice}
    Pour $A$ matrice nilpotente donnée, on pose $\exp(A) \defeq \sum\limits_{k=0}^{+\infty} \frac{A^k}{k!}$.
    \begin{enumerate}
        \item Montrer que si $A$ et $B$ commutent et sont nilpotentes alors $A+B$ est nilpotente et $\exp(A+B) = \exp(A) \times \exp(B)$.
        \item Montrer que $\exp(A)$ est inversible.
        \item Calculer $\exp(A)$ où $A$ est un bloc de \textsc{Jordan}.
    \end{enumerate}
\end{exercice}

\begin{exercice}
    Soient $A \in \M_{3, 2}(\R)$ et $B \in \M_{2, 3}(\R)$ telles que $AB = 
    \begin{pmatrix}
        8 & 2 & -2 \\
        2 & 5 & 4 \\
        -2 & 4 & 5
    \end{pmatrix}
    $. Justifier l'existence de $A$ et $B$ puis calculer $BA$.
\end{exercice}

\begin{exercice}
    Montrer que tout hyperplan de $\M_n(\R)$ contient des matrices inversibles.
\end{exercice}

\begin{exercice}
    Soient $A_1, \dots, A_p$ des matrices distinctes et inversibles de $\M_n(\R)$ telles que $G \defeq \{ A_1, \dots, A_p \}$ soit stable par la multiplication. \\
    Soit $A \defeq A_1 + \cdots + A_p$. Montrer que $\Tr A$ est un entier divisible par $p$.
\end{exercice}

\section{Un endomorphisme nilpotent}

\begin{exercice}
    \marginnote[0cm]{Source : \cite{fmaalouf}}
    Soit $E$ un $\C$-espace vectoriel de dimension finie, $\alpha \in \Ce$, et $f, g$ des endomorphismes de $E$ tels que:
    $$f \circ g - g \circ f = \alpha f \quad \text{et} \quad g \text{ est diagonalisable}.$$
    \begin{enumerate}
        \item Montrer que pour tout entier naturel non nul $n$, $$f^n \circ g - g \circ f^n = n \alpha f^n.$$
        \item En déduire que $f$ est nilpotent. 
    \end{enumerate}
\end{exercice}