\chapter{Algèbre linéaire, Matrices}
\labch{algebre_lineaire_matrices}

\input{chapitres/algebre_lineaire_matrices/intro}

\newpage

% \section{Cours: changement de base}
% \begin{marginfigure}
%     \input{illustrations/i_changement_de_base}
% \end{marginfigure}

% \section{Produit d'endomorphismes nilpotents qui commutent}
% \input{chapitres/algebre_lineaire_matrices/produit_endomorphismes_nilpotents_qui_commutent}

\section{Centre de \texorpdfstring{$\M_n(\K)$}{l'espace des matrices carrées}}
\input{chapitres/algebre_lineaire_matrices/centre_de_l_espace_des_matrices_carres}

\section{Semblables sur \texorpdfstring{$\C$, sur $\R$}{C, sur R}}
\input{chapitres/algebre_lineaire_matrices/semblables_sur_C_sur_R}

\section{Noyaux itérés}
\input{chapitres/algebre_lineaire_matrices/noyaux_iteres}

\section{Applications de \texorpdfstring{$\M_n(\K) \to \K$}{l'espace des matrices carrées dans le corps K} conservant le produit}
\input{chapitres/algebre_lineaire_matrices/applications_de_l_espace_des_matrices_carrees_dans_le_corps_K_conservant_le_produit}

\section{Matrices compagnon et commutant d'un cyclique}
\input{chapitres/algebre_lineaire_matrices/matrices_compagnon_et_commutant_d_un_cyclique}

\section{Caractérisation des homothéties}
\input{chapitres/algebre_lineaire_matrices/caracterisation_des_homotheties}

\section{Polynômes de \textsc{Hilbert}} \label{polynome_hilbert}
\input{chapitres/algebre_lineaire_matrices/polynomes_de_hilbert}

\section{Polynômes de \textsc{Lagrange}} 
\input{chapitres/algebre_lineaire_matrices/polynomes_de_lagrange}

\section{Polynômes d'interpolation de \textsc{Lagrange}, lien avec les déterminants de \textsc{Vandermonde}}
\input{chapitres/algebre_lineaire_matrices/polynomes_interpolation_de_lagrange_lien_avec_les_determinants_de_vandermonde}

\section{Inversion par sommation géométrique des endomorphismes nilpotents} \labsec{inversion_par_sommation_geometrique_des_endomorphismes_nilpotents}
\input{chapitres/algebre_lineaire_matrices/inversion_par_sommation_geometrique_des_endomorphismes_nilpotents}

\section{Matrices de taille \texorpdfstring{$3$}{3} d'ordre de nilpotence égal à \texorpdfstring{$2$}{2}} \labsec{matrices_de_taille_trois_odre_de_nilpotence_deux}
\input{chapitres/algebre_lineaire_matrices/matrices_de_taille_trois_odre_de_nilpotence_deux}

\section{Famille libre engendrée par un endomorphisme nilpotent} \labsec{famille_libre_engendree_par_un_endomorphisme_nilpotent}
\input{chapitres/algebre_lineaire_matrices/famille_libre_engendree_par_un_endomorphisme_nilpotent}

\section{Matrices de rang \texorpdfstring{$1$}{1}}
\input{chapitres/algebre_lineaire_matrices/matrices_de_rang_un}

\section{Sous-espace engendré par les matrices nilpotentes} \labsec{sous_espace_engendre_par_les_matrices_nilpotentes}
\input{chapitres/algebre_lineaire_matrices/sous_espace_engendre_par_les_matrices_nilpotentes}

\section{Produit de matrices nilpotentes commutantes} \labsec{titre_a_completer}
\begin{exercice}
    \marginnote[0cm]{\cite{acamanes}}
    Soient $A$ et $B$ deux matrices de $\M_n(\C)$ qui commutent. 
    \begin{enumerate}
        \item On suppose que $B$ est nilpotente. 
        \begin{enumerate}
            \item Montrer que $A + B$ est inversible si et seulement si $A$ est inversible.
            \item Montrer que $\det(A+B) = \det(A)$.
        \end{enumerate}
        \item Soient $A_1, \dots, A_n$ des matrices nilpotentes qui commutent deux à deux. Montrer que $A_1 \times \cdots \times A_n = 0$.
    \end{enumerate}
\end{exercice}

\begin{solution}
    \begin{enumerate}
        \item Comme les matrices $A$ et $B$ commutent, elles sont cotrigonalisables (lien vers l'exercice correspondant). De plus comme la matrice $B$ est nilpotente, dans toute base dans laquelle elle est triangulaire, sa diagonale est nulle (le spectre d'une matrice nilpotente est réduit à $0$). Ainsi dans une base de cotrigonalisation des matrices $A+B$ et $A$, leur diagonale sont égales et donc leur déterminant (qui sont égaux au produit des termes diagonaux).
        \marginnote[0cm]{
            $$A + B \sim 
            \begin{pmatrix}
                \lambda_1 & \cdots & \star \\
                0 & \ddots & \vdots \\
                0 & 0 & \lambda_n
            \end{pmatrix}
             + 
            \begin{pmatrix}
                0 & \star & \star \\
                0 & \ddots & \star \\
                0 & 0 & 0
            \end{pmatrix}
            $$
        }
        \item \marginnote[0cm]{\cite{reduc_des_endo} p. 117}
        Comme les matrices $A_1, \dots, A_n$ sont trigonalisables et commutent, elles sont cotrigonalisables: il existe donc $T_1, \dots, T_n$ triangulaires supérieures strictes et $P$ inversible telles que $A_i = P T_i \Inv{P_i}$ pour tout $i \in \llbracket 1, n \rrbracket$. \\
        Montrons par récurrence sur $k \in \llbracket 1, n \rrbracket$ que les coefficients en position $(i, j)$ avec $i \geqslant j - k + 1$ de la matrice $T_1 \cdots T_k$ sont nuls. 
        \begin{itemize}
            \item Pour $k=1$, il s'agit simplement de la définition d'une matrice triangulaire supérieure stricte. 
            \item Soit $k \in \llbracket 1, n-1 \rrbracket$ telle que les coefficients en position $(i, j)$ avec $i \geqslant j - k + 1$ de la matrice $T_1 \cdots T_k$ sont nuls. \\
            Soit $(i, j)$ tel que $i \geqslant j - k$. Avec des notation évidentes, 
            \begin{align*}
                [T_1 \cdots T_{k+1}]_{i,j} &= \sum_{\ell=1}^n [T_1 \cdots T_k]_{i, \ell} [T_{k+1}]_{\ell, j} \\
                \text{ comme } T_{k+1} \in \mathscr{T}_n^{++} &= \sum_{\ell=1}^{j-1} [T_1 \cdots T_k]_{i, \ell} [T_{k+1}]_{\ell, j} \\
                &= 0, \text{ car } i \geqslant \ell - k +1.
            \end{align*}
            La récurrence est terminée et l'on en déduit en considérant le cas $k = n$ que la matrice $T_1 \cdots T_n$ est nulle. En conclusion,
            $$A_1 \cdots A_n = P T_1 \cdots T_n \Inv{P} = 0.$$
        \end{itemize}
        \underline{Deuxième démonstration:} \\
        \begin{lemme}
            \marginnote[0cm]{\cite{reduc_des_endo} p. 33}
            Soit $u$ et $n$ deux endomorphismes de $E$ tels que $u$ est non nul, $n$ est nilpotent et $u \circ n = n \circ u$. Montrer que $\Rg(u \circ n) < \Rg(u)$.
        \end{lemme}
        \begin{preuve}
            Comme $u$ et $n$ commutent, $n$ laisse stable $\Im u$. Notons $\widetilde{n}$ l'endomorphisme induit par $n$ sur $\Im u$. Comme $n$ est nilpotent, $\widetilde{n}$ est également nilpotent et donc, en particulier, non inversible. \\
            La formule du rang appliquée à $\widetilde{n}$ donne alors:
            $$\Rg u = \dim \Im u = \Rg \widetilde{n} + \dim \Ker \widetilde{n} > \Rg \widetilde{n}.$$
            On conclut en remarquant que $\Im \widetilde{n} = n(\Im u) = \Im (n \circ u)$.
        \end{preuve}
    \end{enumerate}
\end{solution}


\section{Si \texorpdfstring{$AB - BA = A \dots$}{AB-BA=A...}}
\begin{exercice}
    \marginnote[0cm]{fic00118 [005625]}
    Soit $(A, B) \in \M_n(\R)^2$ tel que $AB-BA=A$. Montrer que pour tout $p \in \Ne$, $\Tr(A^p) = 0$.
\end{exercice}

\marginnote[2cm]{
    \begin{kaobox}[frametitle=Propriétés de la trace]
        Soit $(A, B) \in \M_n(\K)^2$.
        $$\Tr(AB) = \Tr(BA),$$
        $$\Tr(A + \lambda B) = \Tr(A) + \lambda \Tr(B).$$
    \end{kaobox}
}

\begin{solution}
    Soit $p \in \Ne$. On écrit
    \begin{align*}
        A^p = A^{p-1}(AB-BA) = A^pB - A^{p-1}BA.
    \end{align*}
    On composant cette relation par la trace on obtient d'après ses propriétés
    \begin{align*}
        \Tr(A^p) &= \Tr(A^pB) - \Tr((A^{p-1}B)A) \\
        &= \Tr(A^pB) - \Tr(A(A^{p-1}B)) \\
        \Tr(A^p) &= 0.
    \end{align*}
\end{solution}

\begin{exercice} \labexercice{a_comp}
    \marginnote[0cm]{\cite{exos_oraux} p. 47}
    Soient $n \in \Ne$, $A$ et $B$ deux matrices de $\M_n(\R)$ telles que $AB - BA = A.$
    \begin{enumerate}
        \item Montrer que la matrice $A$ n'est pas inversible.
        \item Montrer que pour tout $k \in \Ne$, $AB^k - B^k A = k A^k$. En déduire que la matrice $B$ est nilpotente. 
    \end{enumerate}
\end{exercice}

\begin{remarque}
    On retrouve le résultat (à vérifier et à justifier) qu'une matrice $A$ est nilpotente si et seulement si pour tout $k \in \Ne, \Tr(A^k) = 0$.
\end{remarque}


\section{Application du théorème de recollement}

\begin{exercice}
    \marginnote[0cm]{\cite{acamanes}}
    Soient $E$ et $F$ deux espaces vectoriels de dimension finie et $f \in \Endo(E, F)$. On note 
    $$\mathscr{H} \defeq \{ g \in \Endo(F, E);\ f \circ g \circ f = 0\}.$$ 
    Déterminer la dimension de $\mathscr{H}$ en fonction de $\dim E$, $\dim F$ et $\Rg f$.
\end{exercice}

\marginnote[0cm]{
    \cite{acamanes} Ch3, Th2
    \begin{kaobox}[frametitle=Sommes directe \& Applications linéaires]
        On suppose que $E = \bigoplus\limits_{i=1}^m E_i$. Pour tout indice $i \in \llbracket 1, m \rrbracket$, on considère une application linéaire $\varphi_i$ de $E_i$ dans $F$. Alors, il existe une unique application linéaire $\varphi$ de $E$ dans $F$ telle que pour tout $i \in \llbracket 1, m \rrbracket$, la restriction de $\varphi$ à $E_i$ soit égale à $\varphi$.
    \end{kaobox}
}

\begin{solution}
    \begin{itemize}
        \item On montre que $\mathscr{H}$ est un sous-espace vectoriel de $\Endo(F, E)$. Soit $W$ un supplémentaire de $\Im f$ dans $F$.
        \item Nous allons construire un isomorphisme entre $\mathscr{H}$ et un ensemble dont on peut calculer la dimension. On pose
        \begin{alignat*}{2}
            \psi\ :\ \mathscr{H}\ &\longrightarrow\ \Endo(\Im f, \Ker f) \times \Endo(W, E)\\
            g\ &\longmapsto\ \left(g_{\vert \Im f}, g_{\vert \Ker f} \right).
        \end{alignat*}
        Montrons que $\psi$ est un isomorphisme. 
        \begin{itemize}
            \item[$\rhd$] Montrons que $\psi$ est bien définie: \\
            soient $x \in E$ et $g \in \mathscr{H}$,
            $$\psi(g)(x) = \left( g_{\vert \Im f}(x), g_{\vert W}(x) \right).$$
            De plus, $\Im g \circ f \subset \Ker f$ donc $g_{\vert \Im f} \in \Endo(\Im f, \Ker f)$.
            $$(f \circ g \circ f)(x) = f \Big( g \big (\underbrace{f(x)}_{\defeq y} \big ) \Big) = f \big( \underbrace{g_{\vert \Im f}(y)}_{\in \Ker f} \big) = 0.$$
            La linéarité est triviale. 
            \item[$\rhd$] Montrons que $\psi$ est surjective. \\
            Soit $(g_1, g_2) \in \Endo(\Im f, \Ker f) \times \Endo(W, E)$. \\
            Par théorème de recollement des applications linéaires, il existe une application $g \in \Endo(F, E)$ telle que 
            $
            \begin{cases}
                    g_{\vert \Im f} = g_1 \\
                    g_{\vert W} = g_2
            \end{cases}
            $. \\
            Soit $x \in E$, $(f \circ g \circ f)(x) = f \Big( g \big(\underbrace{f(x)}_{\in \Im f} \big) \Big) = f \Big( \underbrace{g_1 \big(f(x) \big)}_{\in \Ker f} \Big) = 0$ donc $g \in \mathscr{H}$ et $\psi$ est sujective. 
            \item[$\rhd$] Montrons que $\psi$ est injective. \\
            Soit $g \in \Ker \psi$. Alors $\left (g_{\vert \Im f}, g_{\vert W} \right) = \left(0_{\Endo(F, E)}, 0_{\Endo(F, E)} \right)$. \\
            Donc $g = 0_{\Endo(F, E)}$ et $\Ker \psi = \{ 0_{\Endo(F, E)} \}$ soit $\psi$ est injective. \\
            Finalement, $\psi$ est un isomorphisme. \\
            Il y a donc égalité des dimensions entre les espaces de départ et d'arrivée de $\psi$. Ainsi,
            \begin{align*}
                \dim \mathscr{H} &= \dim \big(\Endo(\Im f, \Ker f) \big) + \dim \big( \Endo(W, E) \big) \\
                &= \Rg f \times \dim \Ker f + \dim W \times \dim E \\
                &= \Rg f \times (\dim E - \Rg f) + (\dim F - \Rg f) \times \dim E \\
                \dim \mathscr{H} &= \dim E \dim F - (\Rg f)^2
            \end{align*}
        \end{itemize}
        \begin{remarque}
            Si $\dim E = \dim F$ et que $f$ est bijective, le résultat est cohérent. De même si $f = 0_{\Endo(E, F)}$.
        \end{remarque}
    \end{itemize}
\end{solution}

\underline{Une solution plus visuelle:}

\begin{solution}
    Soit $W$ un supplémentaire de $\Im f$ dans $F$: $\Im f \oplus W = F$ et soit $V$ un supplémentaire de $\Ker f$ dans $E$: $\Ker f \oplus V = E$. \\
    Soit $\mathscr{B} \defeq (e_1, \dots, e_r, e_{r+1}, \dots, e_p)$ une base adaptée à la décomposition $\Im f \oplus W = F$ et soit $\mathscr{B}' \defeq (\varepsilon_1, \dots, \varepsilon_{n-r}, \varepsilon_{n-r+1}, \dots, \varepsilon_n)$ une base adaptée à la décomposition $\Ker f \oplus V = E$.
    \begin{align*}
        g \in \mathscr{H} &\Leftrightarrow g(\Im f) \subset \Ker f \\
        &\Leftrightarrow \Mat_{\mathscr{B}, \mathscr{B}'}(g) = 
        \begin{pmatrix}
            \star & \star \\
            0 & \star
        \end{pmatrix}
    \end{align*}
    à finir....
\end{solution}

\section{Rang des puissances d'un endomorphisme nilpotent} \labsec{rang_des_puissances_d_un_endomorphisme_nilpotent}
\begin{exercice}
    livre à citer \\
    Soient $E$ un $\K$-espace espace vectoriel de dimension $n$ et $u \in \Endo(E)$ nilpotent de rang $n-1$. Déterminer le rang $u^k$ pour $k \in \Ne$. 
\end{exercice}

\begin{solution}
    On a, par hypothèse, $\dim(\Ker u) = 1$ et la chaîne d'inclusions
    $$\{0\} = \Ker(u^0) \subset \Ker(u) \subset \cdots \subset \Ker(u^{n-1}) \subset \Ker(u^n) = E$$
    puis, pour tout $k \geqslant n, \Ker(u^n) = E$. \\
    Si $k \in \llbracket 0, n \rrbracket$ alors 
    \begin{alignat*}{2}
        u_k\ :\ \Ker(u^{k+1})\ &\longrightarrow\ \Ker(u^k)\\
        x\ &\longmapsto\ u(x)
    \end{alignat*}
    définit une application linéaire dont le noyau est $\Ker(u^{k+1}) \cap \Ker(u)$, soit $\Ker(u)$. \\
    Le théorème de rang fournit $\dim(\Ker u^k) \geqslant \Rg u_k = \dim( \Ker u^{k+1}) - 1$ d'où $\dim(\Ker u^{k+1}) - \dim(\Ker u^k) \in \{ 0, 1 \}$. \\
    On en déduit déjà que pour tout $k \in \llbracket 0, n \rrbracket, \dim(\Ker u^k) \leqslant k$. \\
    S'il existe $k$ dans $\llbracket 0, n-1 \rrbracket$ pour lequel $\dim( \Ker u^{k+1}) = \dim(\Ker u^k)$ alors $\Ker u^k = \Ker u^{k+1}$ et, pour $p \in \N$, 
    ...
\end{solution}

\section{Rang d'un endomorphisme nilpotent} \labsec{rang_d_un_endomorphisme_nilpotent}
\begin{exercice}
    Soient $E$ un $\K$-espace vectoriel de dimension $n$, $u \in \Endo(E)$ tel que $u^n = 0$ et $u^{n-1} \not= 0$. Déterminer le rang de $u$.
\end{exercice}

Il s'agit de la réciproque de l'exercice précédent.

\begin{solution}
    D'après l'exercice \textcolor{red}{référence} il existe $x_0 \in E$ tel que la famille $\left( u^k(x_0)\right)_{0 \leqslant k \leqslant n-1}$ est une base de $E$. La matrice de $u$ dans cette base est 
    $$
    \begin{pmatrix}
        0 & \cdots & \cdots & 0 \\
        1 & \ddots & & \vdots \\
        & \ddots & \ddots & \vdots \\
        0 & & 1 & 0
    \end{pmatrix},
    $$
    une matrice de rang $n-1$.
\end{solution}